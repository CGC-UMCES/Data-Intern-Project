{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f800fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "length = len(fnmatch.filter(os.listdir('./individual_day_files/'), '*.csv'))\n",
    "approx_time = length * 1.1\n",
    "print(approx_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab91249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pyproj\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Decorator function to measure the execution time of any function it wraps\n",
    "def measure_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Record the start time before function execution\n",
    "        start_time = time.time()\n",
    "        # Execute the function and capture the result\n",
    "        result = func(*args, **kwargs)\n",
    "        # Record the end time after function execution\n",
    "        end_time = time.time()\n",
    "        # Calculate the total execution time\n",
    "        execution_time = end_time - start_time\n",
    "        # Print the execution time for the function\n",
    "        print(f\"Function {func.__name__} took {execution_time:.8f} seconds to execute.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@measure_execution_time\n",
    "def process_data_with_nested_functions(directory_path, po_file_path, utm_zone=18, utm_hemisphere='N', k=6):\n",
    "    \"\"\"\n",
    "    Main function that processes multiple data files, converts coordinates, and finds the k-nearest neighbors\n",
    "    using nested helper functions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Function to read and preprocess all CSV files in the given directory\n",
    "    def fix_headers(directory_path):\n",
    "        # List all files in the directory that end with .csv\n",
    "        files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "\n",
    "        # Initialize an empty list to hold DataFrames created from each file\n",
    "        dataframes = []\n",
    "        \n",
    "        # Iterate through each file found in the directory\n",
    "        for file in files:\n",
    "            file_path = os.path.join(directory_path, file)\n",
    "\n",
    "            # Extract the day of the year and year from the filename for date calculation\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "            _, day_of_year, year = base_name.split('_')\n",
    "            day_of_year = int(day_of_year)\n",
    "            year = int(year)\n",
    "\n",
    "            # Convert extracted day of the year and year to a standard date format (mm/dd/yyyy)\n",
    "            date = datetime(year, 1, 1) + timedelta(days=day_of_year - 1)\n",
    "            date_str = date.strftime('%m/%d/%Y')\n",
    "\n",
    "            # Read the header lines from the file to create descriptive column names\n",
    "            with open(file_path, 'r') as file:\n",
    "                header_line = file.readline().strip().split()\n",
    "                units_line = file.readline().strip().split()\n",
    "\n",
    "            # Combine the header and unit lines to create detailed column names\n",
    "            merged_header = [f\"{header} ({unit})\" for header, unit in zip(header_line, units_line)]\n",
    "            df = pd.read_csv(file_path, delimiter=r'\\s+', skiprows=2, names=merged_header)\n",
    "\n",
    "            # Add a new column 'date' to the DataFrame using the extracted date\n",
    "            df['date'] = date_str\n",
    "\n",
    "            # Append the processed DataFrame to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "        return dataframes\n",
    "\n",
    "    # Function to add site IDs and convert UTM coordinates to latitude and longitude\n",
    "    def add_site_id_and_convert_utm_to_latlon(dataframes, utm_zone=18, utm_hemisphere='N'):\n",
    "        # Define the coordinate projection from UTM to Latitude/Longitude\n",
    "        utm_proj = pyproj.Proj(proj='utm', zone=utm_zone, ellps='WGS84', datum='WGS84', units='m', north=utm_hemisphere)\n",
    "        lat_lon_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "        # List to store processed DataFrames with added coordinates\n",
    "        processed_dataframes = []\n",
    "        \n",
    "        # Iterate through each DataFrame to process them individually\n",
    "        for df in dataframes:\n",
    "            # Generate a unique site ID for each row in the DataFrame\n",
    "            total_rows = len(df)\n",
    "            site_ids = [f'{i}' for i in range(total_rows)]\n",
    "            df['site_id'] = site_ids\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # Convert UTM coordinates to latitude and longitude if the necessary columns are present\n",
    "            if \"X (UTM)\" in df.columns and \"Y (UTM)\" in df.columns:\n",
    "                lon_model, lat_model = pyproj.transform(utm_proj, lat_lon_proj, df[\"X (UTM)\"].values, df[\"Y (UTM)\"].values)\n",
    "                df['lon_model'] = pd.Series(lon_model)\n",
    "                df['lat_model'] = pd.Series(lat_model)\n",
    "            else:\n",
    "                raise ValueError(\"Columns 'X (UTM)' and 'Y (UTM)' not found in DataFrame\")\n",
    "\n",
    "            # Append the processed DataFrame to the list\n",
    "            processed_dataframes.append(df)\n",
    "\n",
    "        return processed_dataframes\n",
    "\n",
    "    # Function to find the k-nearest neighbors using BallTree for spatial analysis\n",
    "    def find_k_neighbors(dfs, df2, k=6):\n",
    "        # List to hold results of matched neighbors\n",
    "        all_results = []\n",
    "\n",
    "        # Iterate through each DataFrame to find neighbors for each\n",
    "        for df1 in dfs:\n",
    "            # Convert latitude and longitude to radians for spatial computation\n",
    "            coords1 = np.deg2rad(df1[['lat_model', 'lon_model']].values)\n",
    "            tree = BallTree(coords1, metric='haversine')\n",
    "\n",
    "            # Convert df2 coordinates to radians for querying against BallTree\n",
    "            coords2 = np.deg2rad(np.c_[df2['Latitude'], df2['Longitude']])\n",
    "            distances, indices = tree.query(coords2, k=k+1)\n",
    "\n",
    "            # Transpose results to align with indices and distances for matching\n",
    "            distances = distances.transpose()\n",
    "            indices = indices.transpose()\n",
    "\n",
    "            # Select the closest match for each point\n",
    "            closest = indices[0]\n",
    "            closest_dist = distances[0]\n",
    "            df = df1.loc[closest].reset_index(drop=True)\n",
    "            df = df.add_prefix('cs_')  # Prefix columns for clarity\n",
    "\n",
    "            # Prefix columns in df2 for clarity\n",
    "            df2_prefixed = df2.add_prefix('os_')\n",
    "\n",
    "            # Concatenate the matched results\n",
    "            result = pd.concat([df, df2_prefixed], axis=1)\n",
    "            all_results.append(result)\n",
    "\n",
    "        # Combine all individual results into a single DataFrame\n",
    "        final_result = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "        return final_result\n",
    "    \n",
    "    # Function to process the PO4 data by matching dates and site IDs\n",
    "    def process_po4_data(po4_df, ball_tree_df, model_data_df):\n",
    "        # Initialize an empty DataFrame to store matched data\n",
    "        matching_data = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each row in the PO4 DataFrame\n",
    "        for index, po4_row in po4_df.iterrows():\n",
    "            # Extract the SampleDate from the current row\n",
    "            sample_date = po4_row['SampleDate']\n",
    "\n",
    "            # Filter the BallTree DataFrame for rows with matching dates\n",
    "            matching_dates = ball_tree_df[ball_tree_df['cs_date'] == sample_date]\n",
    "\n",
    "            # If matching dates are found, proceed to check the Station ID\n",
    "            if not matching_dates.empty:\n",
    "                station_id = po4_row['Station']\n",
    "\n",
    "                # Filter the matching dates for rows with matching Station IDs\n",
    "                matching_stations = matching_dates[matching_dates['os_MonitoringStation'] == station_id]\n",
    "\n",
    "                # If both date and station match, retrieve the cs_site_id\n",
    "                if not matching_stations.empty:\n",
    "                    cs_site_id = matching_stations.iloc[0]['cs_site_id']\n",
    "\n",
    "                    # Find rows in model_data where both date and site_id match\n",
    "                    matching_model_data = model_data_df[(model_data_df['date'] == sample_date) &\n",
    "                                                        (model_data_df['site_id'] == cs_site_id)]\n",
    "\n",
    "                    # If matching model data is found, combine all relevant data\n",
    "                    if not matching_model_data.empty:\n",
    "                        for _, model_data_row in matching_model_data.iterrows():\n",
    "                            # Combine PO4 row, matching BallTree row, and model data row\n",
    "                            combined_row = pd.concat([po4_row, matching_stations.iloc[0], model_data_row], axis=0)\n",
    "\n",
    "                            # Append the combined row to the final DataFrame\n",
    "                            matching_data = pd.concat([matching_data, combined_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        return matching_data\n",
    "\n",
    "    # Step 1: Fix headers in the data files and add a date column\n",
    "    dataframes = fix_headers(directory_path)\n",
    "    \n",
    "    # Step 2: Load the PO file and filter rows where Depth is less than or equal to 1.0\n",
    "    po = pd.read_csv(po_file_path)\n",
    "    filtered_po = po[po['Depth'] <= 1.0]\n",
    "    \n",
    "    # Step 3: Add site_id and convert UTM coordinates to latitude/longitude for all DataFrames\n",
    "    processed_dataframes = add_site_id_and_convert_utm_to_latlon(dataframes, utm_zone, utm_hemisphere)\n",
    "    \n",
    "    # Step 4: Prepare a unique set of locations from filtered PO data\n",
    "    x = np.array(list(set(tuple(p) for p in filtered_po[['Latitude', 'Longitude', 'MonitoringStation']].values)))\n",
    "    locations_CBP = pd.DataFrame(x, columns=['Latitude', 'Longitude', 'MonitoringStation'])\n",
    "    locations_CBP[\"Longitude\"] = pd.to_numeric(locations_CBP[\"Longitude\"])\n",
    "    locations_CBP[\"Latitude\"] = pd.to_numeric(locations_CBP[\"Latitude\"])\n",
    "    \n",
    "    # Step 5: Find the k nearest neighbors for each location in the processed data\n",
    "    final_result = find_k_neighbors(processed_dataframes, locations_CBP, k=k)\n",
    "    \n",
    "    # Step 6: Load PO4 data and process it using matched results from BallTree\n",
    "    po4_data = pd.read_csv(po_file_path)\n",
    "    matching_po4_data = process_po4_data(po4_data, final_result, pd.concat(processed_dataframes))\n",
    "    \n",
    "    return matching_po4_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = process_data_with_nested_functions('./individual_day_files/', './PO4_wq.csv')\n",
    "print(result)\n",
    "#result.to_csv('new_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
